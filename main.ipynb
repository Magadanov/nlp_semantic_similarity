{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Optimal performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Utilise resources</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Enhance productivity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Conduct an analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Maintain a high standard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Implement best practices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ensure compliance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Streamline operations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Foster innovation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Drive growth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Leverage synergies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Demonstrate leadership</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Exercise due diligence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Maximize stakeholder value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Prioritise tasks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Facilitate collaboration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Monitor performance metrics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Execute strategies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Gauge effectiveness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Champion change</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Optimal performance\n",
       "0             Utilise resources\n",
       "1          Enhance productivity\n",
       "2           Conduct an analysis\n",
       "3      Maintain a high standard\n",
       "4      Implement best practices\n",
       "5             Ensure compliance\n",
       "6         Streamline operations\n",
       "7             Foster innovation\n",
       "8                  Drive growth\n",
       "9            Leverage synergies\n",
       "10       Demonstrate leadership\n",
       "11       Exercise due diligence\n",
       "12   Maximize stakeholder value\n",
       "13             Prioritise tasks\n",
       "14     Facilitate collaboration\n",
       "15  Monitor performance metrics\n",
       "16           Execute strategies\n",
       "17          Gauge effectiveness\n",
       "18              Champion change"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms = pd.read_csv(\"data/Standardised terms.csv\")\n",
    "terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In today's meeting, we discussed a variety of issues affecting our department. The weather was unusually sunny, a pleasant backdrop to our serious discussions. We came to the consensus that we need to do better in terms of performance. Sally brought doughnuts, which lightened the mood. It's important to make good use of what we have at our disposal. During the coffee break, we talked about the upcoming company picnic. We should aim to be more efficient and look for ways to be more creative in our daily tasks. Growth is essential for our future, but equally important is building strong relationships with our team members. As a reminder, the annual staff survey is due next Friday. Lastly, we agreed that we must take time to look over our plans carefully and consider all angles before moving forward. On a side note, David mentioned that his cat is recovering well from surgery.\n"
     ]
    }
   ],
   "source": [
    "with open('data/sample_text.txt', 'r') as f:\n",
    "    sample_text = f.read()\n",
    "print(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\magad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\magad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['today', 'meeting', 'discussed', 'variety', 'issues', 'affecting', 'department'], ['weather', 'unusually', 'sunny', 'pleasant', 'backdrop', 'serious', 'discussions'], ['came', 'consensus', 'need', 'better', 'terms', 'performance'], ['sally', 'brought', 'doughnuts', 'lightened', 'mood'], ['important', 'make', 'good', 'use', 'disposal'], ['coffee', 'break', 'talked', 'upcoming', 'company', 'picnic'], ['aim', 'efficient', 'look', 'ways', 'creative', 'daily', 'tasks'], ['growth', 'essential', 'future', 'equally', 'important', 'building', 'strong', 'relationships', 'team', 'members'], ['reminder', 'annual', 'staff', 'survey', 'due', 'next', 'friday'], ['lastly', 'agreed', 'must', 'take', 'time', 'look', 'plans', 'carefully', 'consider', 'angles', 'moving', 'forward'], ['side', 'note', 'david', 'mentioned', 'cat', 'recovering', 'well', 'surgery']]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "input_text = sample_text\n",
    "def preparing_sentence(sentences):\n",
    "    sentences = [sentence.lower().strip() for sentence in sentences]\n",
    "    sentences = [re.sub(r'[^a-z0-9\\s]', ' ', sentence) for sentence in sentences]\n",
    "    sentences = [[word for word in word_tokenize(sentence) if word not in set(stopwords.words('english'))] for sentence in sentences]\n",
    "    return sentences\n",
    "\n",
    "sentences = sent_tokenize(input_text)\n",
    "sentences = preparing_sentence(sentences)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['utilise resources',\n",
       " 'enhance productivity',\n",
       " 'conduct an analysis',\n",
       " 'maintain a high standard',\n",
       " 'implement best practices',\n",
       " 'ensure compliance',\n",
       " 'streamline operations',\n",
       " 'foster innovation',\n",
       " 'drive growth',\n",
       " 'leverage synergies',\n",
       " 'demonstrate leadership',\n",
       " 'exercise due diligence',\n",
       " 'maximize stakeholder value',\n",
       " 'prioritise tasks',\n",
       " 'facilitate collaboration',\n",
       " 'monitor performance metrics',\n",
       " 'execute strategies',\n",
       " 'gauge effectiveness',\n",
       " 'champion change']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardized_phrases = list(terms['Optimal performance'].values)\n",
    "standardized_phrases = [s.lower() for s in standardized_phrases]\n",
    "standardized_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replace 'came consensus need better terms performance' with 'monitor performance metrics'\n",
      "Replace 'aim efficient look ways creative daily tasks' with 'prioritise tasks'\n",
      "Replace 'growth essential future equally important building strong relationships team members' with 'drive growth'\n",
      "Replace 'reminder annual staff survey due next friday' with 'exercise due diligence'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "standardized_matrix = vectorizer.fit_transform(standardized_phrases)\n",
    "\n",
    "for snt in sentences:\n",
    "    sentence_vector = vectorizer.transform([' '.join(snt)])\n",
    "    similarity_scores = cosine_similarity(sentence_vector, standardized_matrix)\n",
    "    best_match_index = similarity_scores.argmax()\n",
    "    best_match = standardized_phrases[best_match_index]\n",
    "\n",
    "    if similarity_scores[0][best_match_index] > 0.5:\n",
    "        print(f\"Replace '{' '.join(snt)}' with '{best_match}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
